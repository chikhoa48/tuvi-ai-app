import streamlit as st
import google.generativeai as genai
from lunardate import LunarDate
from datetime import datetime

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="Thi√™n C∆° C√°c - T·ª≠ Vi & B√°t T·ª± AI", page_icon="‚òØÔ∏è", layout="wide")

# --- CSS GIAO DI·ªÜN ---
st.markdown("""
<style>
    .tuvi-grid { display: grid; grid-template-columns: repeat(4, 1fr); gap: 5px; background-color: #fce4ec; padding: 10px; border: 2px solid #880e4f; }
    .cung { background-color: white; border: 1px solid #ddd; padding: 10px; min-height: 150px; font-size: 14px; }
    .cung-header { font-weight: bold; color: #b71c1c; text-align: center; border-bottom: 1px solid #eee; margin-bottom: 5px; }
    .center-box { grid-column: 2 / 4; grid-row: 2 / 4; background-color: #fff3e0; display: flex; flex-direction: column; justify-content: center; align-items: center; text-align: center; border: 2px double #e65100; }
    .stChatMessage { background-color: #f1f8e9; }
</style>
""", unsafe_allow_html=True)

# --- KH·ªûI T·∫†O STATE ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "user_data_context" not in st.session_state:
    st.session_state.user_data_context = ""
if "has_run" not in st.session_state:
    st.session_state.has_run = False

# --- SIDEBAR: C·∫§U H√åNH & API KEY ---
with st.sidebar:
    st.header("‚öôÔ∏è C·∫•u h√¨nh H·ªá th·ªëng")
    
    # 1. X·ª≠ l√Ω API Key (∆Øu ti√™n l·∫•y t·ª´ Secrets, n·∫øu kh√¥ng c√≥ th√¨ nh·∫≠p tay)
    api_key = None
    if "GEMINI_API_KEY" in st.secrets:
        st.success("‚úÖ ƒê√£ k·∫øt n·ªëi API Key h·ªá th·ªëng")
        api_key = st.secrets["GEMINI_API_KEY"]
    else:
        api_key = st.text_input("Nh·∫≠p Gemini API Key", type="password", help="Nh·∫≠p xong nh·ªõ nh·∫•n Enter")
        if not api_key:
            st.warning("‚ö†Ô∏è Ch∆∞a nh·∫≠p API Key")
    
    st.divider()
    
    # 2. Ch·ªçn phi√™n b·∫£n AI
    st.subheader("üß† Ch·ªçn Tr√≠ Tu·ªá AI")
    model_option = st.selectbox(
        "Phi√™n b·∫£n Gemini:",
        ("gemini-1.5-flash", "gemini-1.5-pro"),
        index=0,
        help="Flash: Nhanh, m∆∞·ª£t. Pro: Suy lu·∫≠n s√¢u s·∫Øc h∆°n nh∆∞ng ch·∫≠m h∆°n."
    )
    
    st.info(f"ƒêang d√πng: {model_option}")

# --- H√ÄM X·ª¨ L√ù L·ªäCH ---
CAN = ["Gi√°p", "·∫§t", "B√≠nh", "ƒêinh", "M·∫≠u", "K·ª∑", "Canh", "T√¢n", "Nh√¢m", "Qu√Ω"]
CHI = ["T√Ω", "S·ª≠u", "D·∫ßn", "M√£o", "Th√¨n", "T·ªµ", "Ng·ªç", "M√πi", "Th√¢n", "D·∫≠u", "Tu·∫•t", "H·ª£i"]

def get_can_chi(year):
    return f"{CAN[(year + 6) % 10]} {CHI[(year + 8) % 12]}"

def convert_solar_to_lunar(d, m, y):
    lunar = LunarDate.fromSolarDate(y, m, d)
    return lunar

# --- H√ÄM G·ªåI GEMINI AI ---
def ask_gemini(prompt, history=[], model_name="gemini-1.5-flash"):
    if not api_key:
        return "‚ö†Ô∏è L·ªói: Ch∆∞a c√≥ API Key."
    
    genai.configure(api_key=api_key)
    
    # C·∫•u h√¨nh model d·ª±a tr√™n l·ª±a ch·ªçn c·ªßa ng∆∞·ªùi d√πng
    generation_config = {
        "temperature": 0.7,
        "top_p": 0.95,
        "top_k": 64,
        "max_output_tokens": 8192,
    }
    
    try:
        model = genai.GenerativeModel(
            model_name=model_name,
            generation_config=generation_config,
            system_instruction="B·∫°n l√† m·ªôt ƒê·∫°i S∆∞ T·ª≠ Vi v√† B√°t T·ª± th√¢m th√∫y. B·∫°n lu·∫≠n gi·∫£i d·ª±a tr√™n Nam Ph√°i v√† T·ª© Tr·ª• T·ª≠ B√¨nh. Gi·ªçng vƒÉn c·ªï trang, s√¢u s·∫Øc, r√†nh m·∫°ch."
        )
        chat = model.start_chat(history=history)
        response = chat.send_message(prompt)
        return response.text
    except Exception as e:
        return f"‚ùå L·ªói k·∫øt n·ªëi AI: {str(e)}\n(Ki·ªÉm tra l·∫°i API Key ho·∫∑c ƒë·ªïi Model kh√°c)"

# --- GIAO DI·ªÜN CH√çNH ---
st.title("‚òØÔ∏è THI√äN C∆† C√ÅC - LU·∫¨N GI·∫¢I T·ª¨ VI")

col1, col2, col3 = st.columns(3)
with col1:
    name = st.text_input("H·ªç t√™n t√≠n ch·ªß", "Nguy·ªÖn VƒÉn A")
    gender = st.selectbox("Gi·ªõi t√≠nh", ["Nam", "N·ªØ"])
with col2:
    dob = st.date_input("Ng√†y sinh (D∆∞∆°ng)", datetime(1990, 1, 1))
with col3:
    tob = st.time_input("Gi·ªù sinh", datetime.strptime("12:00", "%H:%M").time())

# N√∫t b·∫•m x·ª≠ l√Ω
if st.button("üîÆ L·∫≠p L√° S·ªë & Lu·∫≠n Gi·∫£i", type="primary"):
    # Ki·ªÉm tra Key ngay l·∫≠p t·ª©c
    if not api_key:
        st.error("‚õî Vui l√≤ng nh·∫≠p API Key ·ªü menu b√™n tr√°i v√† nh·∫•n Enter tr∆∞·ªõc khi b·∫•m n√∫t n√†y!")
        st.stop() # D·ª´ng ch∆∞∆°ng tr√¨nh t·∫°i ƒë√¢y, kh√¥ng ch·∫°y ti·∫øp code b√™n d∆∞·ªõi

    with st.spinner(f"ƒê·∫°i s∆∞ ({model_option}) ƒëang b·∫•m ƒë·ªôn... xin ch·ªù gi√¢y l√°t..."):
        # 1. T√≠nh to√°n d·ªØ li·ªáu
        lunar_date = convert_solar_to_lunar(dob.day, dob.month, dob.year)
        can_chi_nam = get_can_chi(lunar_date.year)
        
        user_info = f"""
        TH√îNG TIN:
        - T√™n: {name} ({gender})
        - D∆∞∆°ng l·ªãch: {dob.day}/{dob.month}/{dob.year} - {tob.strftime('%H:%M')}
        - √Çm l·ªãch: {lunar_date.day}/{lunar_date.month}/{lunar_date.year}
        - NƒÉm: {can_chi_nam}
        """
        st.session_state.user_data_context = user_info
        
        # 2. T·∫°o Prompt
        full_prompt = f"""
        {user_info}
        
        Y√äU C·∫¶U ƒê·∫†I S∆Ø ({model_option}):
        1. **L·∫≠p B√°t T·ª±:** X√°c ƒë·ªãnh Can Chi c·ªßa Gi·ªù, Ng√†y, Th√°ng, NƒÉm.
        2. **An Sao (M√¥ ph·ªèng):** X√°c ƒë·ªãnh M·ªánh cung, Th√¢n cung v√† c√°c ch√≠nh tinh t·ªça th·ªß.
        3. **Lu·∫≠n Gi·∫£i:**
           - Ph√¢n t√≠ch Ng≈© h√†nh, d·ª•ng th·∫ßn.
           - Lu·∫≠n v·ªÅ t√≠nh c√°ch, c√¥ng danh, t√†i l·ªôc, t√¨nh duy√™n.
           - V·∫≠n h·∫°n nƒÉm nay.
        4. **L·ªùi khuy√™n:** Phong th·ªßy c·∫£i m·ªánh.
        
        D√πng Markdown tr√¨nh b√†y ƒë·∫πp, d√πng c√°c icon ƒë·∫ßu d√≤ng.
        """
        
        # 3. G·ªçi AI
        response = ask_gemini(full_prompt, model_name=model_option)
        st.session_state.result = response
        st.session_state.has_run = True

# --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
if st.session_state.has_run:
    st.divider()
    tab1, tab2, tab3 = st.tabs(["üìú L√° S·ªë C∆° B·∫£n", "üîÆ L·ªùi B√¨nh C·ªßa ƒê·∫°i S∆∞", "üéì H·ªèi ƒê√°p & Nghi√™n C·ª©u"])
    
    with tab1:
        # Code v·∫Ω l√° s·ªë (Visual)
        cung_names = ["T·ªµ", "Ng·ªç", "M√πi", "Th√¢n", "Th√¨n", "", "", "D·∫≠u", "M√£o", "", "", "Tu·∫•t", "D·∫ßn", "S·ª≠u", "T√Ω", "H·ª£i"]
        html_content = '<div class="tuvi-grid">'
        for i, name_cung in enumerate(cung_names):
            if name_cung == "":
                if i == 5:
                    html_content += f'<div class="center-box"><h3>{name}</h3><p>{can_chi_nam}</p></div>'
                continue
            html_content += f'<div class="cung"><div class="cung-header">Cung {name_cung}</div></div>'
        html_content += '</div>'
        st.markdown(html_content, unsafe_allow_html=True)

    with tab2:
        st.markdown(st.session_state.result)

    with tab3:
        st.info(f"ƒêang tr√≤ chuy·ªán v·ªõi: {model_option}")
        
        for message in st.session_state.chat_history:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input("H·ªèi th√™m v·ªÅ l√° s·ªë..."):
            if not api_key:
                st.error("M·∫•t k·∫øt n·ªëi API Key!")
            else:
                st.session_state.chat_history.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)

                with st.spinner("ƒê·∫°i s∆∞ ƒëang suy ng·∫´m..."):
                    research_prompt = f"Ng·ªØ c·∫£nh l√° s·ªë: {st.session_state.user_data_context}\nC√¢u h·ªèi: {prompt}\nGi·∫£i th√≠ch chi ti·∫øt:"
                    ai_reply = ask_gemini(research_prompt, history=[], model_name=model_option)
                    
                    st.session_state.chat_history.append({"role": "assistant", "content": ai_reply})
                    with st.chat_message("assistant"):
                        st.markdown(ai_reply)
